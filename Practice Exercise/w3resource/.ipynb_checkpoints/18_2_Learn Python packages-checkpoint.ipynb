{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "473b0952-b049-430c-b54b-8ce35cdf4f6f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Python urllib3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991730c9-1bc6-4960-90f1-3a40406cbc6a",
   "metadata": {},
   "source": [
    "Making Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ce89d9b-da58-46cb-b08b-a4575367c046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e04bedd8-6370-47fe-b5ea-2f689cd54e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'User-agent: *\\nDisallow: /deny\\n'\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "res = urllib3.request(\"GET\", \"http://httpbin.org/robots.txt\")\n",
    "print(res.data)\n",
    "print(res.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c42590c-80da-4a1d-b513-dd411b7520c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'User-agent: *\\nDisallow: /deny\\n'\n"
     ]
    }
   ],
   "source": [
    "http = urllib3.PoolManager()\n",
    "res = http.request(\"GET\", \"http://httpbin.org/robots.txt\")\n",
    "print(res.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df558e4f-49cc-49d1-8cfe-f3b1eec19061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\\n<title>405 Method Not Allowed</title>\\n<h1>Method Not Allowed</h1>\\n<p>The method is not allowed for the requested URL.</p>\\n'\n"
     ]
    }
   ],
   "source": [
    "http = urllib3.PoolManager()\n",
    "resp = http.request(\n",
    "    \"GET\",\n",
    "    \"https://httpbin.org/post\",\n",
    "    fields={\"hello\": \"world\"} #  Add custom form fields\n",
    ")\n",
    "\n",
    "print(resp.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35eef687-fa21-4e9a-97b5-64327c266369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\\n  \"args\": {}, \\n  \"data\": \"\", \\n  \"files\": {}, \\n  \"form\": {\\n    \"hello\": \"world\"\\n  }, \\n  \"headers\": {\\n    \"Accept-Encoding\": \"identity\", \\n    \"Content-Length\": \"129\", \\n    \"Content-Type\": \"multipart/form-data; boundary=ca05d707e8f289ec2dfc1d2e7658432f\", \\n    \"Host\": \"httpbin.org\", \\n    \"User-Agent\": \"python-urllib3/2.2.3\", \\n    \"X-Amzn-Trace-Id\": \"Root=1-678104ff-5b7eb6d23d7a4ef666e69e94\"\\n  }, \\n  \"json\": null, \\n  \"origin\": \"123.201.110.130\", \\n  \"url\": \"https://httpbin.org/post\"\\n}\\n'\n"
     ]
    }
   ],
   "source": [
    "http = urllib3.PoolManager()\n",
    "resp = http.request(\n",
    "    \"POST\",\n",
    "    \"https://httpbin.org/post\",\n",
    "    fields={\"hello\": \"world\"} #  Add custom form fields\n",
    ")\n",
    "\n",
    "print(resp.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c9dbd1-465e-47b9-a600-c917ef205b8b",
   "metadata": {},
   "source": [
    "Response content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c40b7153-912e-4627-9d65-0fd2b1618c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "b'{\\n  \"origin\": \"123.201.110.130\"\\n}\\n'\n",
      "HTTPHeaderDict({'Date': 'Fri, 10 Jan 2025 11:38:33 GMT', 'Content-Type': 'application/json', 'Content-Length': '34', 'Connection': 'keep-alive', 'Server': 'gunicorn/19.9.0', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Credentials': 'true'})\n"
     ]
    }
   ],
   "source": [
    "import urllib3\n",
    "\n",
    "# Making the request (The request function returns HTTPResponse object)\n",
    "resp = urllib3.request(\"GET\", \"https://httpbin.org/ip\")\n",
    "\n",
    "print(resp.status)\n",
    "# 200\n",
    "print(resp.data)         # Binary data\n",
    "# b\"{\\n  \"origin\": \"104.232.115.37\"\\n}\\n\"\n",
    "print(resp.headers)\n",
    "# HTTPHeaderDict({\"Content-Length\": \"32\", ...})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6db3614b-5134-429e-a972-a70885558556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'origin': '123.201.110.130'}\n"
     ]
    }
   ],
   "source": [
    "print(resp.json())    # Json data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20a02dd-a563-4ed3-a75f-95660600e0c6",
   "metadata": {},
   "source": [
    "Using io Wrappers with Response Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c086bc27-8399-4ff9-ae39-714cbd951542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html>\n",
      " <html>\n",
      " <head>\n",
      "     <title>Example Domain</title>\n",
      " \n",
      "     <meta charset=\"utf-8\" />\n",
      "     <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" />\n",
      "     <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
      "     <style type=\"text/css\">\n",
      "     body {\n",
      "         background-color: #f0f0f2;\n",
      "         margin: 0;\n",
      "         padding: 0;\n",
      "         font-family: -apple-system, system-ui, BlinkMacSystemFont, \"Segoe UI\", \"Open Sans\", \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
      "         \n",
      "     }\n",
      "     div {\n",
      "         width: 600px;\n",
      "         margin: 5em auto;\n",
      "         padding: 2em;\n",
      "         background-color: #fdfdff;\n",
      "         border-radius: 0.5em;\n",
      "         box-shadow: 2px 3px 7px 2px rgba(0,0,0,0.02);\n",
      "     }\n",
      "     a:link, a:visited {\n",
      "         color: #38488f;\n",
      "         text-decoration: none;\n",
      "     }\n",
      "     @media (max-width: 700px) {\n",
      "         div {\n",
      "             margin: 0 auto;\n",
      "             width: auto;\n",
      "         }\n",
      "     }\n",
      "     </style>    \n",
      " </head>\n",
      " \n",
      " <body>\n",
      " <div>\n",
      "     <h1>Example Domain</h1>\n",
      "     <p>This domain is for use in illustrative examples in documents. You may use this\n",
      "     domain in literature without prior coordination or asking for permission.</p>\n",
      "     <p><a href=\"https://www.iana.org/domains/example\">More information...</a></p>\n",
      " </div>\n",
      " </body>\n",
      " </html>\n",
      " "
     ]
    }
   ],
   "source": [
    "import io\n",
    "import urllib3\n",
    "\n",
    "resp = urllib3.request(\"GET\", \"https://example.com\", preload_content=False)\n",
    "resp.auto_close = False\n",
    "\n",
    "for line in io.TextIOWrapper(resp):\n",
    "    print(line, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd58ef4d-1cb4-4404-ae12-b79def56fb8f",
   "metadata": {},
   "source": [
    "Certificate Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fea83b15-83b0-4d3e-af44-783a3ec1a651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification Failed!!\n"
     ]
    }
   ],
   "source": [
    "import certifi\n",
    "import urllib3\n",
    "\n",
    "http = urllib3.PoolManager(\n",
    "    cert_reqs=\"CERT_REQUIRED\",\n",
    "    ca_certs=certifi.where()\n",
    ")\n",
    "\n",
    "http.request(\"GET\", \"https://httpbin.org/\")\n",
    "# (No exception)\n",
    "\n",
    "try:\n",
    "    http.request(\"GET\", \"https://expired.badssl.com\")\n",
    "    # urllib3.exceptions.SSLError ...\n",
    "except:\n",
    "    print(\"Verification Failed!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e2db42-8328-487e-81b5-e18353cc55fd",
   "metadata": {},
   "source": [
    "Write a Python program that performs a simple HTTP GET request to a public API (e.g., JSONPlaceholder) and prints the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0f152b7-16a6-48cf-ab86-cb62679e939a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Data:\n",
      "{\n",
      "  \"userId\": 1,\n",
      "  \"id\": 1,\n",
      "  \"title\": \"sunt aut facere repellat provident occaecati excepturi optio reprehenderit\",\n",
      "  \"body\": \"quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import urllib3\n",
    "\n",
    "# Create a PoolManager instance to manage HTTP connections\n",
    "http = urllib3.PoolManager()\n",
    "\n",
    "# Define the API endpoint URL\n",
    "api_url = 'https://jsonplaceholder.typicode.com/posts/1'\n",
    "\n",
    "# Make a GET request to the API endpoint\n",
    "response = http.request('GET', api_url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status == 200:\n",
    "    # Print the response data (decoded as UTF-8)\n",
    "    print(\"Response Data:\")\n",
    "    print(response.data.decode('utf-8'))\n",
    "else:\n",
    "    # Print an error message if the request was not successful\n",
    "    print(f\"Error: Unable to fetch data. Status Code: {response.status}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c19100f-aa2c-458a-a601-66fcaebba85f",
   "metadata": {},
   "source": [
    "Write a Python program that performs a simple HTTP GET request to a public API (e.g., JSONPlaceholder) and prints the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a828b6e3-d882-4bc7-909a-c1cb8df5c446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response Data:\n",
      "{\n",
      "  \"userId\": 1,\n",
      "  \"id\": 1,\n",
      "  \"title\": \"sunt aut facere repellat provident occaecati excepturi optio reprehenderit\",\n",
      "  \"body\": \"quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import urllib3\n",
    "\n",
    "http = urllib3.PoolManager()\n",
    "\n",
    "api_url = 'https://jsonplaceholder.typicode.com/posts/1'\n",
    "\n",
    "response = http.request('GET', api_url)\n",
    "\n",
    "if response.status == 200:\n",
    "    print(\"Response Data:\")\n",
    "    print(response.data.decode('utf-8'))\n",
    "else:\n",
    "    print(f\"Error: Unable to fetch data. Status Code: {response.status}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc96c060-bfb6-4d4e-a53a-700917e6ca19",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Python GeoPy Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd6c5190-4b86-432f-bf0c-c1c7879b3126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"geoapi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08764747-9932-4328-a932-4529d71dcd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address: Tour Eiffel, 5, Avenue Anatole France, Quartier du Gros-Caillou, Paris 7e Arrondissement, Paris, France métropolitaine, 75007, France\n",
      "Coordinates: (48.8582599, 2.2945006358633115)\n"
     ]
    }
   ],
   "source": [
    "location = geolocator.geocode(\"Eiffel Tower, Paris\")\n",
    "print(f\"Address: {location.address}\")\n",
    "print(f\"Coordinates: ({location.latitude}, {location.longitude})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddf58e2d-4310-4e95-8b87-b779f820ace3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address: Anjar, NH341, Sainath Digital, અંજાર, Anjar Taluka, Kutch, Gujarat, 370110, India\n",
      "Coordinates: (23.1194278, 70.0363797)\n"
     ]
    }
   ],
   "source": [
    "location = geolocator.geocode(\"Anjar\")\n",
    "print(f\"Address: {location.address}\")\n",
    "print(f\"Coordinates: ({location.latitude}, {location.longitude})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f83bfcd-d532-4cc2-91ea-aed911187b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anjar, NH341, Sainath Digital, અંજાર, Anjar Taluka, Kutch, Gujarat, 370110, India\n"
     ]
    }
   ],
   "source": [
    "location = geolocator.reverse('23.1194278, 70.0363797')\n",
    "print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac4e678b-2464-4012-b264-306d329c5114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance: 6491.89 km\n"
     ]
    }
   ],
   "source": [
    "from geopy.distance import geodesic\n",
    "\n",
    "location1 = (48.8566, 2.3522)  # Paris\n",
    "location2 = (23.1194278, 70.0363797)  # Anjar\n",
    "\n",
    "distance = geodesic(location1, location2).kilometers\n",
    "print(f\"Distance: {distance:.2f} km\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f3f917-b24c-4859-ba4c-563195911084",
   "metadata": {},
   "source": [
    "Write a Python program to search the Street address, name from a given location information using Nominatim API and GeoPy package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93d4e88e-8caf-4b12-a08a-a23170344fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"geoapi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d638b1d3-5371-43db-bc7f-2ad95b148165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address: Adajan Taluka, Surat, Gujarat, India\n",
      "Coordinates: (21.2651204, 72.84991282218647)\n"
     ]
    }
   ],
   "source": [
    "location = geolocator.geocode(\"Adajan, Surat\")\n",
    "\n",
    "print(f\"Address: {location.address}\")\n",
    "print(f\"Coordinates: ({location.latitude}, {location.longitude})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b16b465-0ac1-4509-b121-56df346ab482",
   "metadata": {},
   "source": [
    "Write a Python program to find the location address of a specified latitude and longitude using Nominatim API and Geopy package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "461739c7-995e-4001-aab8-4a5cc9c51d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"geoapi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b764779-0aea-4f45-ab63-0e6db8db0611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anjar, NH341, Sainath Digital, અંજાર, Anjar Taluka, Kutch, Gujarat, 370110, India\n"
     ]
    }
   ],
   "source": [
    "location = geolocator.reverse('23.1194278, 70.0363797')\n",
    "print(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d256e4fb-8951-48d5-93b8-2d6dd9c141bf",
   "metadata": {},
   "source": [
    " Write a Python program to calculate the distance between London and New York city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4924c77-e2a3-4d20-a7ca-d78d2857558d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between London and New York city (in km):\n",
      "5585.2335789313  kms\n"
     ]
    }
   ],
   "source": [
    "from geopy import distance\n",
    "\n",
    "london = (\"51.5074° N, 0.1278° W\")\n",
    "newyork = (\"40.7128° N, 74.0060° W\")\n",
    "\n",
    "print(\"Distance between London and New York city (in km):\")\n",
    "print(distance.distance(london, newyork).km,\" kms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d6415a-e698-4b4b-9ba1-5ff48cfbd106",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Python Metaprogramming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8124f1-fd1d-48d0-9b69-792d504a7e35",
   "metadata": {},
   "source": [
    "Write a Python program to create a metaclass \"UpperAttrMeta\" that converts all attribute names of a class to uppercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20d1bd28-f1df-48d8-845f-9430387c1e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "bar\n"
     ]
    }
   ],
   "source": [
    "# Define a metaclass that converts all attribute names to uppercase\n",
    "class UpperAttrMeta(type):\n",
    "    def __new__(cls, name, bases, dct):\n",
    "        # Create a new dictionary to store uppercase attributes\n",
    "        uppercase_attr = {}\n",
    "        for name, value in dct.items():\n",
    "            if not name.startswith('__'):\n",
    "                # Convert attribute name to uppercase\n",
    "                uppercase_attr[name.upper()] = value\n",
    "            else:\n",
    "                # Preserve special methods as they are\n",
    "                uppercase_attr[name] = value\n",
    "        # Create the new class with modified attributes\n",
    "        return super().__new__(cls, name, bases, uppercase_attr)\n",
    "\n",
    "# Create a class using the metaclass\n",
    "class MyClass(metaclass=UpperAttrMeta):\n",
    "    foo = 'bar'\n",
    "    baz = 'qux'\n",
    "\n",
    "# Test the class\n",
    "print(hasattr(MyClass, 'foo'))  # False, because attribute names are uppercase\n",
    "print(hasattr(MyClass, 'FOO'))  # True, because 'foo' is converted to 'FOO'\n",
    "print(MyClass.FOO)  # 'bar', accessing the uppercase attribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c871aef-3558-4735-a304-63f979cff74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "setattr(MyClass, 'name', 'Jeet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "884c9fed-c970-4712-b041-c7f1a8657203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BAZ',\n",
       " 'FOO',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'name']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(MyClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ede6122b-0b9b-436b-bfd1-1950aa7bb7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(MyClass, 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15398421-95c7-4eba-89ff-61b18315dab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jeet'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyClass.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48ac8d90-d086-480a-a79f-585a2a1fb459",
   "metadata": {},
   "outputs": [],
   "source": [
    "delattr(MyClass, 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ee9b8fdf-3d17-4ef2-9896-494ccfbd3468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(MyClass, 'name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2a305c-d34e-44a1-a0d5-8bd6ed7a4fdd",
   "metadata": {},
   "source": [
    "Creating Classes Dynamically:\n",
    "\n",
    "Write a Python function “create_class” that takes a class name and a dictionary of attributes and methods, and returns a dynamically created class with those attributes and methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17d59b60-55be-45b3-b75d-1653e991f68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Jeet Prajapati!\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "# Function to create a class dynamically with specified attributes and methods\n",
    "def create_class(name, attrs):\n",
    "    # Use the type function to create a new class with the given name, inheriting from object, and using the specified attributes and methods\n",
    "    return type(name, (object,), attrs)\n",
    "\n",
    "# Define attributes and methods for the dynamic class\n",
    "attrs = {\n",
    "    # Add a method 'greet' that returns a greeting string\n",
    "    'greet': lambda self: \"Hello, Jeet Prajapati!\",\n",
    "    # Add an attribute 'age' with value 25\n",
    "    'age': 21\n",
    "}\n",
    "\n",
    "# Create a class dynamically using the defined attributes and methods\n",
    "MyDynamicClass = create_class('MyDynamicClass', attrs)\n",
    "\n",
    "# Test the dynamic class\n",
    "# Create an instance of the dynamically created class\n",
    "instance = MyDynamicClass()\n",
    "# Call the 'greet' method of the instance\n",
    "print(instance.greet())  # Output: \"Hello, Sonia Toutatis!\"\n",
    "# Access the 'age' attribute of the instance\n",
    "print(instance.age)  # Output: 25 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693c8daa-d9d1-4eee-a072-da148b449d02",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Python Arrow Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6496b51-2479-4d02-8fd9-25ab56d74356",
   "metadata": {},
   "source": [
    "Write a Python program to get the current UTC datetime, local datetime and datetime of a given location using arrow module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4cfa493e-b649-46f9-ade8-d215bc8b0073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current datetime:\n",
      "2025-01-16T05:24:53.515097+00:00\n",
      "\n",
      "Current local datetime:\n",
      "2025-01-16T10:54:53.515097+05:30\n",
      "\n",
      "Specified local datetime (Asia/Kolkata):\n",
      "2025-01-16T10:54:53.516096+05:30\n"
     ]
    }
   ],
   "source": [
    "import arrow\n",
    "\n",
    "a = arrow.utcnow()\n",
    "print(\"Current datetime:\")\n",
    "print(a)\n",
    "\n",
    "print(\"\\nCurrent local datetime:\")\n",
    "b = arrow.now()\n",
    "print(b)\n",
    "\n",
    "print(\"\\nSpecified local datetime (Asia/Kolkata):\")\n",
    "c = arrow.now('Asia/Kolkata')\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f797d4e8-8838-41f4-906d-a852bc1a5aa0",
   "metadata": {},
   "source": [
    "Write a Python program to create datetime from integers, floats and strings timestamps using arrow module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1765879a-76fd-45ae-9ae8-3b795d25b242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date from integers: \n",
      "2028-11-15T11:29:05+00:00\n",
      "\n",
      "Date from floats: \n",
      "2028-11-15T11:29:05.234323+00:00\n",
      "\n",
      "Date from Strings: \n",
      "2025-01-16T00:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "import arrow\n",
    "\n",
    "i = arrow.get(1857900545)\n",
    "print(\"Date from integers: \")\n",
    "print(i)\n",
    "\n",
    "f = arrow.get(1857900545.234323)\n",
    "print(\"\\nDate from floats: \")\n",
    "print(f)\n",
    "\n",
    "s = arrow.get('2025-01-16')\n",
    "print(\"\\nDate from Strings: \")\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9831313-9a3f-4acc-9f87-c69620bd9b80",
   "metadata": {},
   "source": [
    "Write a Python program to search a date from a given string using arrow module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed810ee5-7f19-4e77-9555-af1e5edc365e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search a date from a string:\n",
      "2003-06-11T00:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "import arrow\n",
    "\n",
    "print(\"\\nSearch a date from a string:\")\n",
    "d1 = arrow.get('David was born in 11 June 2003', 'DD MMMM YYYY')\n",
    "print(d1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "72ab5708-e520-4a58-9145-ab5432329c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Arrow.timestamp of <Arrow [2003-06-11T00:00:00+00:00]>>\n"
     ]
    }
   ],
   "source": [
    "print(d1.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ca33aa4-237d-4a8c-94a5-ce3bb6d31518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d4be316-7e70-4890-83d9-b177744c5ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2003"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "87274bd9-365b-4552-88f4-9626f0869337",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = d1.replace(year=2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "11ac9bed-b9fe-4317-a646-61d5f411c35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2025"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b028ccf7-7368-421a-8d35-45d4b37b9eb9",
   "metadata": {},
   "source": [
    "# Python Natural Language Toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86b46fd-baa2-44b7-993f-2a438e7a7611",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h2> NLTK Tokenize</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c580e8c-1af1-4326-83bf-3244b29640b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\JeetPrajapati\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "819c696e-6629-47e8-8ee7-53ef18aa96c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original string:\n",
      "\n",
      "Joe waited for the train. The tra\n",
      "in was late. \n",
      "Mary and Samantha took the bus. \n",
      "I looked for Mary and Samantha at the b\n",
      "us station.\n",
      "\n",
      "\n",
      "Sentence-tokenized copy in a list:\n",
      "['\\nJoe waited for the train.', 'The tra\\nin was late.', 'Mary and Samantha took the bus.', 'I looked for Mary and Samantha at the b\\nus station.']\n",
      "\n",
      "Read the list:\n",
      "\n",
      "Joe waited for the train.\n",
      "The tra\n",
      "in was late.\n",
      "Mary and Samantha took the bus.\n",
      "I looked for Mary and Samantha at the b\n",
      "us station.\n"
     ]
    }
   ],
   "source": [
    "text = '''\n",
    "Joe waited for the train. The tra\n",
    "in was late. \n",
    "Mary and Samantha took the bus. \n",
    "I looked for Mary and Samantha at the b\n",
    "us station.\n",
    "'''\n",
    "\n",
    "print(\"\\nOriginal string:\")\n",
    "print(text)\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "token_text = sent_tokenize(text)\n",
    "\n",
    "print(\"\\nSentence-tokenized copy in a list:\")\n",
    "print(token_text)\n",
    "\n",
    "print(\"\\nRead the list:\")\n",
    "for s in token_text:\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48be9b66-0b3c-42fa-8a3d-4d24008f6544",
   "metadata": {},
   "source": [
    "Write a Python NLTK program to create a list of words from a given string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b971a063-8028-4654-b050-e977cd7dcdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original string:\n",
      "Joe waited for the train. The train was late. Mary and Samantha took the bus. I looked for Mary and Samantha at the bus station.\n",
      "\n",
      "List of words:\n",
      "['Joe', 'waited', 'for', 'the', 'train', '.', 'The', 'train', 'was', 'late', '.', 'Mary', 'and', 'Samantha', 'took', 'the', 'bus', '.', 'I', 'looked', 'for', 'Mary', 'and', 'Samantha', 'at', 'the', 'bus', 'station', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"Joe waited for the train. The train was late. Mary and Samantha took the bus. I looked for Mary and Samantha at the bus station.\"\n",
    "print(\"\\nOriginal string:\")\n",
    "print(text)\n",
    "\n",
    "print(\"\\nList of words:\")\n",
    "print(word_tokenize(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d98a25-b115-44d2-afc8-134b57cdbd3e",
   "metadata": {},
   "source": [
    "<h2>NLTK Corpus</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7370606-1d2e-430b-99cc-1578dcf52b1c",
   "metadata": {},
   "source": [
    "Write a Python NLTK program to list down all the corpus names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbb9cf3d-5a61-4b90-b4b0-ee2688b691a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available corpus names:\n",
      "['_LazyModule__lazymodule_globals', '_LazyModule__lazymodule_import', '_LazyModule__lazymodule_init', '_LazyModule__lazymodule_loaded', '_LazyModule__lazymodule_locals', '_LazyModule__lazymodule_name', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__']\n"
     ]
    }
   ],
   "source": [
    "import nltk.corpus\n",
    "\n",
    "print(\"\\nAvailable corpus names:\")\n",
    "print(dir(nltk.corpus))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55bb3ef-f3a1-4d8c-a9a0-b74562073d1e",
   "metadata": {},
   "source": [
    "Write a  Python  NLTK program to get a list of common stop words in various languages in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68428747-ddb1-4945-9784-4699caae3fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\JeetPrajapati\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfb9de19-6bca-48c8-b22d-e1b37e6df962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arabic', 'azerbaijani', 'basque', 'bengali', 'catalan', 'chinese', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hebrew', 'hinglish', 'hungarian', 'indonesian', 'italian', 'kazakh', 'nepali', 'norwegian', 'portuguese', 'romanian', 'russian', 'slovene', 'spanish', 'swedish', 'tajik', 'turkish']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "print (stopwords.fileids())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a128c5-e434-4a1b-abfc-a84c9fc1296c",
   "metadata": {},
   "source": [
    "\n",
    "Write a Python NLTK program to check the list of stopwords in various languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "464433d5-f354-426e-b952-86ce8b30c2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of stopwords in English:\n",
      "{\"it's\", 'who', \"needn't\", 'your', 'up', 'does', 'himself', 'had', \"couldn't\", 'doesn', 'then', 'same', 'each', 'hasn', 'couldn', 'did', 'further', 'them', 'will', 'they', 'down', 'm', 'both', 'her', 'because', 'mightn', 'and', 'these', 'needn', 'y', 'yourselves', 'at', 'd', 'aren', \"hadn't\", 'whom', 'more', 'having', 'as', 'under', 'of', 'not', 'themselves', 'this', 'ma', 'by', 'ours', 'or', 'when', \"mightn't\", 'myself', 'me', 'are', \"hasn't\", 'he', 'most', 're', 'his', 'won', \"you'll\", 't', 'so', 'ain', 'out', 'why', \"didn't\", 'hers', 'll', 'only', 'below', \"you're\", 'mustn', 'too', 'until', 'we', 'ourselves', 'their', 'about', 'where', \"mustn't\", 'for', 'off', 'such', 'which', \"haven't\", 'that', \"that'll\", 'how', 'than', 've', 'the', 'once', 'against', 'herself', 'with', 'what', \"don't\", 'wasn', \"doesn't\", 'theirs', 'in', 'all', 'isn', 'have', 'shan', \"won't\", 'to', 'am', 'doing', 'some', 'other', 'yourself', 'be', 'any', 'but', 'it', \"shouldn't\", 'own', 'our', 'its', 'were', 'while', 'do', 'on', 'few', 'wouldn', 'very', 'she', 'has', 'between', 'didn', 'before', 'shouldn', 'nor', 'above', \"weren't\", \"shan't\", 'my', 'been', 'here', 'i', 'through', \"you've\", 'can', 'weren', 'him', \"you'd\", 'was', 'now', 'a', 'itself', \"isn't\", \"she's\", 'should', \"wouldn't\", 'from', 'no', 'just', \"aren't\", 'being', 'again', 'haven', 'there', 'after', \"wasn't\", 'an', 'into', 'o', 'hadn', 'yours', 's', 'don', 'those', 'over', 'during', 'you', \"should've\", 'if', 'is'}\n",
      "\n",
      "List of stopwords in Arabic:\n",
      "{'منها', 'آه', 'كليكما', 'هاهنا', 'يوليو', 'رأى', 'مما', 'مئتان', 'جوان', 'مهما', 'أل', 'هي', 'إنما', 'خمسين', 'آض', 'عشر', 'آ', 'إما', 'أوشك', 'بَلْهَ', 'عما', 'ثمنمئة', 'أمام', 'كم', 'قاطبة', 'شبه', 'سوى', 'أولاء', 'يونيو', 'أن', 'كثيرا', 'هل', 'إيانا', 'أوّهْ', 'أطعم', 'مليم', 'تسعون', 'بكم', 'لئن', 'جيم', 'أربعمئة', 'اللذين', 'عدَّ', 'إذاً', 'هذي', 'خمسمائة', 'قاف', 'تسع', 'انبرى', 'شتان', 'كما', 'ا', 'ظنَّ', 'وُشْكَانَ', 'غداة', 'على', 'بكن', 'كلا', 'أنًّ', 'ضاد', 'هيهات', 'كأين', 'لستم', 'طالما', 'جنيه', 'ذاك', 'ظلّ', 'هَاتِه', 'مايو', 'هذان', 'آهِ', 'تانِ', 'كلتا', 'رويدك', 'سبت', 'دال', 'أيّ', 'رجع', 'هَذِه', 'ذه', 'لكي', 'ذيت', 'ليست', 'أول', 'نعم', 'طَق', 'هاتان', 'أنشأ', 'أكثر', 'رزق', 'حقا', 'كِخ', 'هن', 'إي', 'هاك', 'هاتين', 'تفعلون', 'سبعين', 'وَيْ', 'حمدا', 'بهما', 'ذانك', 'تلقاء', 'شمال', 'بسّ', 'في', 'مادام', 'ذِي', 'إياي', 'هيّا', 'ألا', 'فو', 'فإذا', 'ثان', 'أُفٍّ', 'سادس', 'آهٍ', 'يفعلان', 'ذلكما', 'ثلاثمئة', 'زعم', 'أفعل به', 'مرّة', 'شَتَّانَ', 'أضحى', 'أكتوبر', 'سبعة', 'ثلاثين', 'إحدى', 'سرعان', 'كأنما', 'ل', 'كيت', 'نوفمبر', 'ت', 'كأيّن', 'أعطى', 'تاسع', 'منه', 'معاذ', 'ثمة', 'تسعمئة', 'إنَّ', 'آي', 'تسعين', 'هنا', 'ئ', 'أفٍّ', 'حبيب', 'كذا', 'أخبر', 'أمّا', 'لمّا', 'واهاً', 'لاسيما', 'هذا', 'إياكما', 'لعلَّ', 'قام', 'فضلا', 'خامس', 'إذا', 'فلان', 'هاته', 'تجاه', 'عدا', 'لهما', 'اخلولق', 'اللذان', 'تَيْنِ', 'إياهم', 'هؤلاء', 'إيه', 'حيثما', 'هلا', 'آناء', 'ها', 'ذوا', 'ظ', 'واو', 'ما انفك', 'ما أفعله', 'بعدا', 'إذن', 'إلى', 'تِي', 'بخٍ', 'التي', 'ث', 'شرع', 'أنى', 'أبدا', 'خلف', 'صبرا', 'هلم', 'سبحان', 'هما', 'هَذَيْنِ', 'بلى', 'عيانا', 'ارتدّ', 'ولو', 'خمسمئة', 'نَخْ', 'صبر', 'سنتيم', 'كن', 'راح', 'سبع', 'خلافا', 'اللتين', 'إذما', 'لها', 'أنبأ', 'آهاً', 'كلَّا', 'ثامن', 'دواليك', 'ثمانية', 'أقبل', 'لدن', 'ي', 'بماذا', 'ذواتا', 'أم', 'ذلك', 'فيما', 'لست', 'رابع', 'بضع', 'خاء', 'إلَيْكَ', 'صاد', 'عاد', 'آمينَ', 'لبيك', 'هبّ', 'أنتن', 'فرادى', 'ما برح', 'ذَيْنِ', 'هَجْ', 'نيسان', 'اثنا', 'بي', 'غ', 'عامة', 'بمن', 'ّأيّان', 'علًّ', 'كأنّ', 'إياها', 'جمعة', 'ألف', 'ين', 'ستون', 'علم', 'تموز', 'مكانكم', 'أيا', 'ة', 'إليكنّ', 'أ', 'أما', 'ساء', 'زاي', 'أمامك', 'هَيْهات', 'لنا', 'هللة', 'أقل', 'أيها', 'يا', 'إلا', 'أغسطس', 'سابع', 'ثلاثمائة', 'كأي', 'إنا', 'بها', 'يفعلون', 'إياكن', 'ذهب', 'أبٌ', 'لدى', 'وإذا', 'جير', 'هناك', 'تفعلين', 'عند', 'خمس', 'تبدّل', 'هاتي', 'جانفي', 'ذا', 'أنت', 'حيث', 'مازال', 'بس', 'ذي', 'ثالث', 'عَدَسْ', 'يناير', 'وإذ', 'لكم', 'أربعة', 'ز', 'بخ', 'سبعمائة', 'آها', 'أفريل', 'حمٌ', 'فاء', 'عن', 'والذين', 'ء', 'وا', 'فمن', 'أبريل', 'ليرة', 'ذال', 'إليكما', 'ريال', 'منذ', 'هَاتانِ', 'إياك', 'صار', 'علق', 'أبو', 'بنا', 'كأن', 'ستين', 'بك', 'لولا', 'ست', 'تحوّل', 'أيّان', 'كليهما', 'سرا', 'تحت', 'عشرين', 'مع', 'خاصة', 'لك', 'س', 'بطآن', 'لوما', 'ثاني', 'اربعون', 'انقلب', 'ماذا', 'أمامكَ', 'لم', 'قبل', 'عليه', 'ص', 'ؤ', 'ذين', 'اربعين', 'ثمان', 'هَذا', 'سحقا', 'رُبَّ', 'حرى', 'أين', 'ذلكن', 'عشرون', 'هو', 'ع', 'دينار', 'اتخذ', 'بَسْ', 'إيهٍ', 'استحال', 'كي', 'لكيلا', 'من', 'فلا', 'ذو', 'ى', 'أى', 'هم', 'ثمانون', 'أمد', 'صباح', 'مكانكما', 'طرا', 'حيَّ', 'أنتما', 'إى', 'ك', 'تي', 'تسعة', 'ميم', 'سمعا', 'أمس', 'ن', 'إن', 'سقى', 'أجل', 'إنه', 'ق', 'فيها', 'لام', 'لو', 'بهن', 'أنتِ', 'ثاء', 'جلل', 'إياهن', 'كرب', 'همزة', 'أمسى', 'ج', 'اللتان', 'دولار', 'خ', 'أنا', 'ب', 'خبَّر', 'سبعمئة', 'دونك', 'عشرة', 'بئس', 'قلما', 'لعل', 'لي', 'بات', 'هَاتِي', 'ضحوة', 'جعل', 'هاكَ', 'دون', 'إياهما', 'ريث', 'صهْ', 'إليكن', 'هاء', 'جميع', 'بغتة', 'ستة', 'ستمائة', 'فبراير', 'إزاء', 'عليك', 'أو', 'ومن', 'تينك', 'سوف', 'هنالك', 'وجد', 'تعسا', 'تين', 'ط', 'أصلا', 'ذات', 'صراحة', 'طاء', 'تلكما', 'ترك', 'هيت', 'حين', 'درى', 'أوه', 'حجا', 'قرش', 'تعلَّم', 'نون', 'بؤسا', 'ستمئة', 'فيفري', 'ولكن', 'ثلاثاء', 'غير', 'هكذا', 'درهم', 'مكانَك', 'بعض', 'حسب', 'أينما', 'نفس', 'ألفى', 'و', 'حدَث', 'أعلم', 'ظاء', 'تارة', 'ح', 'لعمر', 'حبذا', 'خميس', 'مذ', 'ورد', 'مئة', 'ولا', 'غالبا', 'تفعلان', 'هَاتَيْنِ', 'ثمّ', 'لكنَّ', 'ثمّة', 'ثمَّ', 'حاشا', 'خال', 'إياكم', 'الألى', 'آذار', 'غدا', 'الذي', 'اللتيا', 'له', 'إليكَ', 'ذلكم', 'إليكم', 'وإن', 'اثنين', 'كذلك', 'بكما', 'كيف', 'ش', 'لكما', 'حزيران', 'أسكن', 'إلّا', 'اللائي', 'ف', 'كل', 'شباط', 'غين', 'فيه', 'وهو', 'لكنما', 'مارس', 'وراءَك', 'ثمانين', 'حاء', 'نيف', 'ليسا', 'كانون', 'ته', 'خلا', 'بين', 'أصبح', 'طاق', 'هَذانِ', 'سبتمبر', 'ه', 'تشرين', 'ليستا', 'أحد', 'لا سيما', 'ذِه', 'تلكم', 'سبعون', 'هذه', 'حاي', 'كلما', 'كسا', 'سين', 'فوق', 'إياه', 'ءَ', 'تاء', 'شيكل', 'نَّ', 'أهلا', 'ر', 'ابتدأ', 'ثم', 'ثلاثون', 'لستن', 'شين', 'والذي', 'حتى', 'كلاهما', 'مافتئ', 'اثني', 'أنتم', 'حَذارِ', 'كاف', 'م', 'لما', 'راء', 'عل', 'بما', 'لسن', 'حادي', 'حمو', 'طفق', 'ثمانمئة', 'نحو', 'أربع', 'الآن', 'تخذ', 'قطّ', 'كأيّ', 'لسنا', 'أولئك', 'كى', 'مائة', 'غادر', 'كلّما', 'مكانكنّ', 'لا', 'لهن', 'ذ', 'عين', 'أرى', 'خمسة', 'بل', 'لستما', 'أيلول', 'ياء', 'هَذِي', 'ديسمبر', 'عاشر', 'شتانَ', 'لات', 'تلك', 'كيفما', 'د', 'أيار', 'ذان', 'وهب', 'أيضا', 'فلس', 'إمّا', 'هَؤلاء', 'لن', 'مثل', 'هلّا', 'تانِك', 'ليت', 'كان', 'هذين', 'ماي', 'عوض', 'أربعمائة', 'آنفا', 'بيد', 'متى', 'كاد', 'الذين', 'لكن', 'نبَّا', 'آب', 'تسعمائة', 'عسى', 'مساء', 'اثنان', 'خمسون', 'أف', 'أي', 'ذواتي', 'بعد', 'الألاء', 'زود', 'به', 'فيم', 'واحد', 'قد', 'ما', 'اللاتي', 'نا', 'ذانِ', 'بهم', 'يورو', 'ثماني', 'أنّى', 'إذ', 'حار', 'تِه', 'ممن', 'ليسوا', 'اللواتي', 'صدقا', 'أوت', 'ثلاث', 'وما', 'ثلاثة', 'أولالك', 'إليك', 'هيا', 'أجمع', 'ض', 'عجبا', 'أخذ', 'أربعاء', 'فإن', 'باء', 'مه', 'ليس', 'صهٍ', 'أخو', 'ذينك', 'لهم', 'جويلية', 'أخٌ', 'يمين', 'نحن', 'يوان'}\n",
      "\n",
      "List of stopwords in nepali:\n",
      "{'को', 'पहिल्यै', 'जुन', 'साथै', 'गरेको', 'नत्र', 'कम से कम', 'तिनिहरुलाई', 'देखे', 'दोस्रो', 'निम्न', 'पछिल्लो', 'यद्यपि', 'सही', 'कुनै', 'चाले', 'पर्याप्त', 'बने', 'सक्छ', 'पहिले', 'तेस्रो', 'भर', 'आफूलाई', 'जसमा', 'पटक', 'गरेर', 'छौं', 'दिनुभएको', 'जसबाट', 'तदनुसार', 'लगभग', 'देखि', 'छैन', 'गर्छु', 'बिशेष', 'चाहनुहुन्छ', 'गयौ', 'अन्यत्र', 'सायद', 'माथि', 'तथा', 'के', 'छ', 'केही', 'यसो', 'सट्टा', 'जस्तो', 'गर्ने', 'कि', 'तत्काल', 'पर्छ', 'पछि', 'रूप', 'आए', 'बीचमा', 'धेरै', 'राख्छ', 'देखेर', 'एकदम', 'हुने', 'भन्', 'जबकि', 'भन्नुभयो', 'आफ्नै', 'जसले', 'गरि', 'बाहेक', 'मात्र', 'भएको', 'अलग', 'दिनुहुन्छ', 'यहाँ', 'संगै', 'अर्थात्', 'स्पष्ट', 'त', 'भन', 'तिनीहरू', 'निर्दिष्ट', 'का', 'यथोचित', 'अर्को', 'मुख्य', 'पूर्व', 'संग', 'उनको', 'त्यहाँ', 'छु', 'साँच्चै', 'बरु', 'अन्य', 'देखियो', 'अरु', 'तुरुन्तै', 'शायद', 'जसलाई', 'गर्दै', 'अगाडी', 'भन्छन्', 'यहाँसम्म', 'त्यो', 'ठीक', 'राखे', 'गरेका', 'भित्र', 'जो', 'गैर', 'तेस्कारण', 'गर्नुपर्छ', 'भने', 'तल', 'बाहिर', 'गरौं', 'कोही', 'चाहिए', 'रही', 'तिमी', 'सबैलाई', 'उप', 'गर्न', 'र', 'कसै', 'उदाहरण', 'देखेको', 'जाहिर', 'यस्तो', 'आत्म', 'कसैले', 'भन्छु', 'यी', 'थिएन', 'अरुलाई', 'त्सैले', 'यसपछि', 'आफ्नो', 'कृपया', 'यदि', 'गए', 'तिनी', 'पनि', 'पाँच', 'थिए', 'सधै', 'लाई', 'कहिलेकाहीं', 'बीच', 'बिरुद्ध', 'हुन्छ', 'क्रमशः', 'कसरी', 'पहिलो', 'नजिकै', 'पर्थ्यो', 'यसबाहेक', 'या', 'समय', 'हो', 'तर', 'मा', 'प्रति', 'ओठ', 'म', 'अब', 'रहेको', 'त्सपछि', 'नै', 'हुन', 'मलाई', 'जस्तोसुकै', 'वरीपरी', 'चार', 'अक्सर', 'तापनी', 'आदि', 'भए', 'प्लस', 'फेरी', 'नौ', 'वास्तवमा', 'भन्ने', 'तिर', 'सम्भव', 'पक्का', 'एउटै', 'तपाई', 'रहेका', 'देखिन्छ', 'जसको', 'लागि', 'यति', 'कुरा', 'जस्तै', 'सम्म', 'सात', 'पक्कै', 'आफू', 'अन्तर्गत', 'छन्', 'जान', 'हुन्', 'उनले', 'आजको', 'भन्दा', 'मेरो', 'ती', 'सारा', 'हरे', 'सबै', 'यसको', 'किनभने', 'जताततै', 'यस', 'न', 'पाँचौं', 'ले', 'राम्रो', 'अझै', 'तीन', 'औं', 'गरी', 'तिनीहरुको', 'साथ', 'बारे', 'थियो', 'उहालाई', 'कतै', 'छू', 'अन्यथा', 'गर्नु', 'सोही', 'निम्नानुसार', 'किन', 'जब', 'नि', 'तपाईको', 'हरेक', 'सो', 'प्रतेक', 'कहाँबाट', 'जे', 'दिए', 'भित्री', 'अनुसार', 'यसरी', 'चाहन्छु', 'जहाँ', 'नयाँ', 'अर्थात', 'दुई', 'यो', 'निम्ति', 'एक', 'आयो', 'गर्छ'}\n",
      "\n",
      "List of stopwords in hinglish:\n",
      "{'who', 'up', 'waali', 'hoge', \"couldn't\", 'himself', 'jinhone', 'thoda', 'without', 'mean', 'jin', 'willing', 'kinki', 'acha', 'sara', 'second', 'hasn', 'jahaan', 'lagti', 'said', 'get', 'them', 'whose', 'her', 'teeno', 'bht', 'everyone', 'shall', 'banaye', 'aaj', 'rather', 'normally', 'di', 'jinke', 'across', 'kahaan', 'whom', 'nai', 'more', 'yes', 'ask', 'banayi', 'not', 'rhaa', 'whenever', 'hoyengi', 'among', 'this', 'upar', 'vahan', 'nine', 'saying', 'ap', 'whereas', 'bolo', 'inc', 'rha', \"who's\", 'when', 'beside', 'ke', \"mightn't\", 'dhang', 'aisa', 'nahi', \"it'd\", 'hota', 'yahaan', 'dont', \"i'll\", 'yehi', 'jabh', \"can't\", 'mai', 'less', 'bolte', 'kitna', 'tumhara', 'bani', 'most', 'teesre', 'diyaa', 'aadi', 'dunga', 'two', 'shouldnt', 'apna', 'sabse', 'iske', 'ise', 'k', 'nahin', 'jo', 'kull', 'never', 'tab', \"we're\", 'karenge', 'mustn', 'only', 'hither', 'far', 'kiska', 'sent', 'kar', 'like', 'konsa', 'unhone', 'un', 'jahan', 'kayi', 'lagta', 'havent', 'hoga', 'ie', 'anywhere', 'hai', 'off', 'kyaa', 'followed', 'tune', \"haven't\", 'neeche', 'that', 'than', 'wahin', 'karunga', 've', 'need', 'really', 'the', 'aati', 'thats', 'apan', 'used', 'against', 'aisi', \"don't\", 'unless', 'wasn', 'what', 'hamari', 'with', 'anyway', 'bhai', 'dwaara', 'unko', 'isn', 'kaisi', \"won't\", 'to', 'am', 'dono', 'dusra', 'yup', 'be', 'inkaa', 'bola', 'mil', 'mein', 'vahin', \"shouldn't\", 'inka', 'usne', 'logon', 'tha', 'bas', 'jinn', 'say', 'they', 'were', 'yah', 'following', 'ought', 'anyways', 'aint', 'maani', 'kab', 'liya', 'werent', 'waisa', 'iss', 'didn', 'inki', 'teri', 'furthermore', 'banao', 'above', 'boli', \"shan't\", 'regards', 'my', 'namely', 'hua', 'i', 'vaisi', 'others', 'gone', 'through', 'avum', 'placed', 'kin', 'cannot', 'chal', 'hum', 'fir', 'waha', 'mjhe', \"wouldn't\", 'accha', 'waise', 'diyo', 'no', 'thereupon', 'ye', 'appear', 'just', 'again', 'being', 'puri', 'kul', 'kino', 'rhe', 'banai', 'jaha', 'rhi', 'sa', 'vaisa', 'har', 'kiye', 'unhi', 'hue', 'howbeit', 'reasonably', 'kabhi', 'mat', 'sakti', 'hadn', 's', 'causes', 'tumhare', 'those', 'over', 'dvara', 'li', 'kise', 'hadnt', 'if', 'know', 'jidhar', 'oh', 'hereupon', \"it's\", 'apnaa', 'main', 'does', 'whether', 'wherein', 'people', 'else', 'nowhere', 'lately', 'sang', 'true', 'us', 'usi', 'hereafter', 'another', 'karna', 'lo', 'pura', 'further', 'amongst', 'will', 'kaunsa', 'fifth', \"they've\", 'saw', 'umm', 'and', 'waisi', 'dede', 'bc', 'poori', 'couldnt', 'needn', 'tujhe', 'dekha', 'apni', \"c'mon\", 'kara', 'krna', 'kuch', 'liked', 'aren', 'rakhe', 'y', 'everything', 'yourselves', 'abhi', 'hadd', 'whereby', 'certain', 'yaha', 'aap', 'somewhere', 'unho', 'jise', 'hongi', 'still', 'themselves', 'kaisa', 'way', 'follows', 'unhe', 'usse', 'anyhow', 'sure', 'kahaa', 'jiske', 'ltd', 'sub', 'kis', 'ityadi', 'sup', 'wale', 'getting', 'agar', 'much', 'tabh', \"they're\", 'bole', 'issi', 'honaa', 'myself', 'phli', 'rakho', 'whatever', 'unse', 'beforehand', 'pehli', 'are', 'thank', 'khud', 'merely', 'nope', \"we'd\", 'jaisi', 'jaisa', 'his', \"you'll\", 'kiski', 'self', 'might', 'saath', 'ain', 'sath', 'so', 'yet', 'already', 'maane', 'come', 'jaise', 'nhi', 'otherwise', 'somehow', 'dusri', \"i've\", 'pe', 'vo', \"where's\", 'why', 'kine', 'goes', 'bhitar', 'inhi', 'doosre', 'thru', 'tere', 'gaya', 'thorough', 'de', 'lekar', 'rahi', 'take', 'tum', 'kisne', 'asking', 'kinhe', 'third', 'for', 'liye', 'tries', 'which', 'bane', 'kaun', 'yeah', 'rakhen', 'kinko', 'once', 'dekho', 'try', 'secondly', 'must', 'hardly', 'also', 'throughout', 'tarah', 'rahaa', 'bohot', 'doosra', 'rakha', 'outside', 'onto', 'theirs', 'going', 'whoever', 'anybody', 'all', 'would', 'kitno', 'various', 'became', 'huh', 'ne', 'teen', 'some', 'everywhere', 'unkaa', 'dude', 'yahan', 'forth', 'lest', 'tera', 'abe', 'jinhe', 'uses', 'bandi', 'own', \"i'm\", 'kahte', 'best', 'shant', 'knows', 'baad', 'humne', 'while', 'kaafi', 'on', 'almost', 'didnt', 'mustnt', 'good', 'thanx', 'ones', 'unka', 'idk', 'chaiye', 'hogi', 'nor', 'bande', 'itna', 'karega', 'able', 'even', 'toh', 'herein', 'little', 'could', 'hamara', 'somebody', \"you've\", 'according', 'kehte', 'ya', 'a', 'yadi', 'inke', 'thing', 'should', 'usually', 'bana', 'inasmuch', 'wagaira', 'look', 'anyone', 'kahan', 'from', 'hereby', 'hm', 'karu', 'krne', 'looking', 'quite', \"aren't\", \"we've\", 'regardless', 'clearly', 'thinking', 'nd', 'kahi', 'says', 'sometime', 'along', 'into', 'necessary', 'karti', \"let's\", 'o', 'banaya', 'hamare', 'many', 'ka', 'aside', 'become', 'besides', 'during', 'ki', 'mera', \"ain't\", \"should've\", 'uske', 'is', 'within', 'neither', 'diya', \"needn't\", 'kinho', 'your', 'towards', 'doesn', 'then', 'waala', 'kiya', 'right', 'theres', 'dijiye', 'iska', 'hu', 'karungi', 'meri', 'behind', 'isski', 'seen', 'did', 'inn', 'jis', 'several', 'lunga', 'becoming', 'next', 'm', 'aye', 'mightnt', 'new', 'because', 'enough', 'mightn', 'these', 'abbey', 'dekhe', 'accordingly', 'alone', 'gotten', 'cause', 'old', 'at', \"hadn't\", 'ja', 'jinka', 'gets', 'as', 'banae', 'of', 'isi', 'seem', 'si', 'dekh', 'by', 'neednt', 'ussi', 'however', 'since', 'or', 'inse', 'whole', 'honi', 'using', 'kuchch', 'nevertheless', 'mani', 'jitne', 'le', 'seeing', 'least', 'nobody', 'ityaadi', 'wahi', 'tjhe', 'wasnt', 'baar', 'first', 'obviously', 'please', 'dungi', 'seemed', 'karo', 'ghar', 'isme', 'novel', 'andar', 'karni', 'out', 'regarding', 'vale', 'bolta', 'mere', 'ex', 'someone', 'afterwards', 'hers', 'kuchh', 'etc', 'anything', 'below', 'until', 'sometimes', 'hmm', 'ourselves', 'provides', 'bheetar', 'kiske', 'hui', 'thoroughly', 'itni', 'karegi', 'allows', 'happens', 'serious', 'achcha', 'saktaa', 'aur', 'how', 'taken', 'hone', 'hence', 'que', 'tell', 'cant', 'theek', 'woh', 'um', 'herself', 'becomes', 'karne', 'karke', \"doesn't\", 'iskaa', 'na', 'wagairah', 'in', 'vahaan', 'kal', 'ko', \"there's\", 'aya', 'have', 'last', 'vaale', 'looks', 'doing', 'bad', 'other', 'any', 'took', 'hamne', 'it', 'yeh', 'naa', 'inhe', 'help', \"it'll\", 'itno', 'its', 'around', 'degi', 'chalega', 'kyunki', 'do', 'wahan', 'eight', 'few', 'phle', 'rakhi', 'wouldn', 'ever', 'wo', 'has', 'wont', 'tends', 'teesri', 'aise', 'lagte', 'before', 'kinka', 'raha', 'bata', 'saara', 'alag', 'rakh', 'bahut', 'kaise', 'elsewhere', 'kch', 'truly', 'pata', 'go', 'keep', 'maine', 'mujhe', 'diye', \"that's\", 'tried', 'viz', 'weren', 'humein', 'well', 'aaya', 'overall', 'apne', \"isn't\", 'jyada', \"she's\", 'meanwhile', 'thereby', 'bolti', 'per', 'haven', 'kinn', 'jiss', 'name', 'rahe', 'selves', 'hello', 'after', 'huye', 'kafi', 'thanks', 'trying', 'tho', 'wagerah', \"wasn't\", 'jiska', 'seems', 'yahin', 'wali', 'ri', 'vala', 'yours', 'han', 'rehte', 'jitni', 'mano', 'though', 'four', 'wants', 'chahiye', 'keh', 'imo', 'poora', 'com', 'mainly', 'eg', 'thodi', 'whence', 'non', 'kisi', 'seeming', 'haan', 'btw', 'wherever', 'kare', 'had', 'use', 'huyi', 'jinhi', 'same', 'gives', 'noone', 'kari', 'may', 'each', 'often', 'let', 'couldn', 'every', 'kya', 'perhaps', 'went', 'unlikely', 'uska', 'wala', 'apart', 'down', 'hoyenge', 'both', 'jab', \"i'd\", 'jayega', 'jyaada', 'dwara', 'kyu', 'pehla', 'uss', 'none', 'except', 'phla', 'saare', 'd', 'kisko', 'itne', 'thereafter', 'moreover', 'honge', 'having', 'log', 'under', 'doesnt', 'allow', \"what's\", 'isse', 'karta', 'maana', 'par', 'se', \"here's\", 'inho', 'inward', 'nearly', \"they'll\", 'likely', 'jisse', 'ours', 'hasnt', 'got', 'came', 'known', \"they'd\", 'hona', 'kaha', 'teesra', 'denge', 'thought', 'unki', 'isne', 'maybe', 'kitne', 'me', 'sakte', 'vahi', \"hasn't\", 'he', 'example', 're', 'seriously', 'hun', 'near', 'won', 't', 'therefore', 'upon', 'mostly', 'sab', 'hain', 'unn', 'naah', 'arent', 'vaali', \"didn't\", 'bilkul', 'vaala', 'gaye', 'exactly', 'll', 'kon', 'arre', 'whereupon', \"you're\", 'too', 'soon', 'better', 'beyond', 'we', 'karun', 'their', 'about', 'comes', 'where', 'somewhat', \"mustn't\", 'vaise', 'sahi', 'aaye', 'abbe', 'yahi', 'thus', 'such', 'kept', 'vali', 'hote', 'unke', \"that'll\", 'gayi', 'keeps', 'mana', 'kyuki', 'downwards', 'whereafter', 'banda', 'waale', 'greetings', 'jisme', 'kitni', 'koyi', 'okay', 'jitna', 'something', 'tumhari', 'actually', 'inner', 'six', 'plus', 'jaa', 'bhi', 'jata', 'aapne', 'nothing', 'sakta', 'done', 'shan', 'toward', 'koi', 'see', 'wouldnt', 'certainly', 'chhaiye', 'yourself', 'ok', 'but', 'maan', 'everybody', 'together', 'twice', 'our', 'kinke', 'think', 'hotaa', 'magar', 'needs', 'jiski', 'karte', 'edu', 'between', 'dvaara', 'she', 'very', \"we'll\", 'insofar', 'lol', 'shouldn', 'although', 'bol', \"weren't\", 'hoti', 'aata', 'bro', 'dega', 'mane', 'been', 'either', 'here', 'batao', 'thence', 'kisliye', 'lekin', 'can', 'dekhi', 'him', 'now', 'was', \"you'd\", 'dusre', 'sensible', 'therein', 'tu', 'later', 'iski', 'itself', 'pehle', 'want', 'thik', 'hopefully', 'soch', 'wahaan', 'three', 'always', 'there', 'kyun', 'seven', 'via', \"he's\", 'maano', 'thi', 'an', 'five', 'jinki', 'hi', 'ho', 'kahin', 'wohi', 'brief', 'q', 'ab', 'ek', 'useful', 'karen', 'kam', 'given', 'tak', 'unto', 'one', 'th', 'jinho', 'you', 'isnt', 'sabhi'}\n"
     ]
    }
   ],
   "source": [
    "result = set(stopwords.words('english'))\n",
    "print(\"List of stopwords in English:\")\n",
    "print(result)\n",
    "\n",
    "print(\"\\nList of stopwords in Arabic:\")\n",
    "result = set(stopwords.words('arabic'))\n",
    "print(result)\n",
    "\n",
    "print(\"\\nList of stopwords in nepali:\")\n",
    "result = set(stopwords.words('nepali'))\n",
    "print(result)\n",
    "\n",
    "print(\"\\nList of stopwords in hinglish:\")\n",
    "result = set(stopwords.words('hinglish'))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96acff9-b257-4581-b53f-45dc9d883e82",
   "metadata": {},
   "source": [
    "Write a Python NLTK program to remove stop words from a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3614a488-e19d-4b9a-8187-d0a700483d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original string:\n",
      "\n",
      "In computing, stop words are words which are filtered out before or after \n",
      "processing of natural language data (text). Though \"stop words\" usually \n",
      "refers to the most common words in a language, there is no single universal \n",
      "list of stop words used by all natural language processing tools, and \n",
      "indeed not all tools even use such a list. Some tools specifically avoid \n",
      "removing these stop words to support phrase search.\n",
      "\n",
      "\n",
      "After removing stop words from the said text:\n",
      "['computing,', 'stop', 'words', 'words', 'filtered', 'processing', 'natural', 'language', 'data', '(text).', 'Though', '\"stop', 'words\"', 'usually', 'refers', 'common', 'words', 'language,', 'single', 'universal', 'list', 'stop', 'words', 'used', 'natural', 'language', 'processing', 'tools,', 'indeed', 'tools', 'even', 'use', 'list.', 'tools', 'specifically', 'avoid', 'removing', 'stop', 'words', 'support', 'phrase', 'search.']\n"
     ]
    }
   ],
   "source": [
    "stoplist = stopwords.words('english')\n",
    "\n",
    "text = '''\n",
    "In computing, stop words are words which are filtered out before or after \n",
    "processing of natural language data (text). Though \"stop words\" usually \n",
    "refers to the most common words in a language, there is no single universal \n",
    "list of stop words used by all natural language processing tools, and \n",
    "indeed not all tools even use such a list. Some tools specifically avoid \n",
    "removing these stop words to support phrase search.\n",
    "'''\n",
    "\n",
    "print(\"\\nOriginal string:\")\n",
    "print(text)\n",
    "\n",
    "clean_word_list = [word for word in text.split() if word.lower() not in stoplist]\n",
    "print(\"\\nAfter removing stop words from the said text:\")\n",
    "print(clean_word_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b48307-3276-4400-b067-a6957643cf51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
